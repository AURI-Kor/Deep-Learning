{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jR26RFkwXtvi"
      },
      "source": [
        "# **Language Model**\n",
        "2023-02-01\n",
        "\n",
        "1. DataLoader\n",
        "2. Model\n",
        "3. Trainer\n",
        "4. Generation\n",
        "\n",
        " RNN기반의 Language Model 구현 & 텍스트 생성\n",
        "\n",
        "- dataset: WikiText2 (https://github.com/pytorch/examples/tree/master/word_language_model/data/wikitext-2)\n",
        "- model: LSTM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crVJ36mMlaXP"
      },
      "source": [
        "\n",
        "\n",
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqVdEuPQzMAH",
        "outputId": "882b32b4-5bc6-42f5-f6ab-dc1881403694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.1+cu116\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2o3-HPdHLZma"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import tqdm\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "# for reproducibility\n",
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T1GnKJCB4T_Q"
      },
      "source": [
        "# 1. DataLoader"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wcNl0aWbS0OA"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "데이터셋은 Wikipedia에 있는 영문 글들을 가져온 WikiTree dataset\n",
        "불러올 데이터는 WikiTree dataset에서 <자주 사용되지 않는 단어>나 <영어가 아닌 단어>들은 <unk>으로 이미 전처리가 되어있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CKf8zNuISiC2"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "with urllib.request.urlopen('https://raw.githubusercontent.com/yunjey/pytorch-tutorial/master/tutorials/02-intermediate/language_model/data/train.txt') as f:\n",
        "    data = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBLNOlRKSpOI",
        "outputId": "4d840c8e-6578-4adc-8be9-23b6fb3303b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_sentence: 42068\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "b\" plans that give advertisers discounts for maintaining or increasing ad spending have become permanent <unk> at the news <unk> and underscore the fierce competition between newsweek time warner inc. 's time magazine and <unk> b. <unk> 's u.s. news & world report \\n\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('num_sentence:',len(data))\n",
        "data[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "OfLTv1EPbSwj",
        "outputId": "5453fe35-0d48-4b77-f346-b4e337240ea9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "seq_length_list = []\n",
        "for line in data:\n",
        "    seq_length_list.append(len(line.split()))\n",
        "\n",
        "counts, bins = np.histogram(seq_length_list, bins=20)\n",
        "plt.hist(bins[:-1], bins, weights=counts)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4SdattmOcRwC"
      },
      "source": [
        "데이터에 있는 문장 길이들의 histogram을 볼 때 대부분의 data의 문장 길이가 50에 미치지 못하기 때문에 \\\\\n",
        "model에 집어넣을 최대 문장 길이를 50으로 세팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g7MuFqsKcd4U"
      },
      "outputs": [],
      "source": [
        "max_seq_len = 50"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IyMpsyX8TwYy"
      },
      "source": [
        "### Build Dictionary\n",
        "\n",
        "text에 존재하는 단어들을 index로 변환한다.\n",
        "\n",
        "이를 위해서 단어를 index로 변환해주는 word2idx dictionary와 다시 index를 단어로 변환해주는 idx2word dictionary를 구현\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cZmyZhcpTvZz"
      },
      "outputs": [],
      "source": [
        "def build_dictionary(data, max_seq_len):\n",
        "    word2idx = {}\n",
        "    idx2word = {}\n",
        "    ## Build Dictionary\n",
        "    word2idx['<pad>'] = 0\n",
        "    word2idx['<unk>'] = 1\n",
        "    idx2word[0] = '<pad>'\n",
        "    idx2word[1] = '<unk>'\n",
        "    idx = 2\n",
        "    for line in data:\n",
        "        words = line.decode('utf-8').split()\n",
        "        words = words[:max_seq_len]        \n",
        "        ### Build Dictionary to convert word to index and index to word\n",
        "        ### YOUR CODE HERE (~ 5 lines)\n",
        "        for word in words:\n",
        "            if word not in word2idx:\n",
        "                word2idx[word] = idx\n",
        "                idx2word[idx] = word\n",
        "                idx += 1\n",
        "\n",
        "    return word2idx, idx2word\n",
        "\n",
        "word2idx, idx2word = build_dictionary(data, max_seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPfV0OTc4Xdr",
        "outputId": "cd9262c9-86af-44ce-d55a-bc22b3c5b3e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Passed!\n"
          ]
        }
      ],
      "source": [
        "if len(word2idx) == len(idx2word) == 10000:\n",
        "    print(\"Test Passed!\")\n",
        "else:\n",
        "    raise AssertionError"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "me_m8njoXHrv"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "text로된 데이터셋을 index들로 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I6fuARgzXEDU"
      },
      "outputs": [],
      "source": [
        "def preprocess(data, word2idx, idx2word, max_seq_len):\n",
        "    tokens = []\n",
        "    for line in data:\n",
        "        words = line.decode('utf-8').split()\n",
        "        words = words[:max_seq_len]\n",
        "        ### Convert dataset with tokens\n",
        "        ### For each line, append <pad> token to match the number of max_seq_len\n",
        "        ### YOUR CODE HERE (~ 4 lines)\n",
        "        words += ['<pad>']*(max_seq_len - len(words))\n",
        "        for word in words:\n",
        "            token = word2idx[word]\n",
        "            tokens.append(token)\n",
        "\n",
        "    return tokens\n",
        "\n",
        "tokens = preprocess(data, word2idx, idx2word, max_seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjyvqMgbZnfP",
        "outputId": "15050165-2feb-4184-81c7-2ad58e613aa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Passed!\n"
          ]
        }
      ],
      "source": [
        "if len(tokens) == 2103400:\n",
        "    print(\"Test Passed!\")\n",
        "else:\n",
        "    raise AssertionError"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jmQxX3BH-SAv"
      },
      "source": [
        "전처리된 Token들을 문장 단위의 배열로 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knMvtp23-Jye",
        "outputId": "2083001d-e9fb-46c5-eae8-2b9a907fde26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(42068, 50)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([745,  93, 746, 739, 747, 181, 748, 467, 749, 740, 750, 154, 751,\n",
              "       752,   1, 160,  32, 753,   1,  48, 754,  32, 755, 756, 757, 728,\n",
              "       555, 758,  99, 119, 555, 733,  48,   1, 759,   1, 119, 237, 753,\n",
              "       230, 760, 347,   0,   0,   0,   0,   0,   0,   0,   0])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = np.array(tokens).reshape(-1, max_seq_len)\n",
        "print(tokens.shape)\n",
        "tokens[100]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pceBqmtTZ9g9"
      },
      "source": [
        "### DataLoader\n",
        "\n",
        "Token형태의 데이터를 PyTorch 스타일 dataset으로 만들 때 주의점 : embedding matrix에서 indexing을 해주기 위해서 각 token이 LongTensor 형태로 정의되어야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1hAwhG1K9iBI"
      },
      "outputs": [],
      "source": [
        "class LMDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tokens):\n",
        "        super(LMDataset, self).__init__()\n",
        "        self.PAD = 0\n",
        "        self.UNK = 1\n",
        "        self.tokens = tokens\n",
        "        self._getitem(2)\n",
        "\n",
        "    def _getitem(self, index):\n",
        "        X = self.tokens[index]\n",
        "        y = np.concatenate((X[1:], [self.PAD]))\n",
        "\n",
        "        X = torch.from_numpy(X).unsqueeze(0).long()\n",
        "        y = torch.from_numpy(y).unsqueeze(0).long()\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.tokens[index]\n",
        "        y = np.concatenate((X[1:], [self.PAD]))\n",
        "\n",
        "        X = torch.from_numpy(X).long()\n",
        "        y = torch.from_numpy(y).long()\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiLNqM6kAda1",
        "outputId": "4a3ca49e-87f7-47d3-9dc0-ec3fc2f7b8fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42068\n",
            "658\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "dataset = LMDataset(tokens)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(len(dataset))\n",
        "print(len(dataloader))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b1nhBnqWxw4a"
      },
      "source": [
        "# 2. Model\n",
        "\n",
        "**Language Modeling을 위한 Recurrent Model**\n",
        "\n",
        "Standard한 Recurrent Neural Network (RNN) model은 vanishing gradient 문제에 취약하기 때문에, 변형된 RNN구조인 LSTM model을 활용\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aOoNVt3MDOjl"
      },
      "source": [
        "### LSTM\n",
        "\n",
        "https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YDNAysVqxxOk"
      },
      "outputs": [],
      "source": [
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(LSTMCell, self).__init__()\n",
        "        # input-gate\n",
        "        self.Wi = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        # forget-gate\n",
        "        self.Wf = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        # gate-gate\n",
        "        self.Wg = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        # output-gate\n",
        "        self.Wo = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "        # non-linearity\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x, h_0, c_0):\n",
        "        \"\"\"\n",
        "        Inputs\n",
        "            input (x): [batch_size, input_size]\n",
        "            hidden_state (h_0): [batch_size, hidden_size]\n",
        "            cell_state (c_0): [batch_size, hidden_size]\n",
        "        Outputs\n",
        "            next_hidden_state (h_1): [batch_size, hidden_size]\n",
        "            next_cell_state (c_1): [batch_size, hidden_size]    \n",
        "        \"\"\"\n",
        "        h_1, c_1 = None, None\n",
        "        input = torch.cat((x, h_0), 1)\n",
        "        # Implement LSTM cell as noted above\n",
        "        ### YOUR CODE HERE (~ 6 lines)\n",
        "        i = self.sigmoid(self.Wi(input))\n",
        "        f = self.sigmoid(self.Wf(input))\n",
        "        g = self.tanh(self.Wg(input))\n",
        "        o = self.sigmoid(self.Wo(input))\n",
        "        c_1 = f * c_0 + i * g\n",
        "        h_1 = o * self.tanh(c_1)\n",
        "\n",
        "        return h_1, c_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0Tff2VCJ56D",
        "outputId": "766191b6-f09f-4820-a167-a16ca31a70bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==LSTM cell test passed!==\n"
          ]
        }
      ],
      "source": [
        "def test_lstm():\n",
        "    batch_size = 2\n",
        "    input_size = 5\n",
        "    hidden_size = 3\n",
        "\n",
        "    #torch.manual_seed(1234)\n",
        "    lstm = LSTMCell(input_size ,hidden_size)\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            torch.nn.init.constant_(m.weight, 0.1)\n",
        "            m.bias.data.fill_(0.01)\n",
        "    lstm.apply(init_weights)\n",
        "\n",
        "    x = torch.ones(batch_size, input_size)\n",
        "    hx = torch.zeros(batch_size, hidden_size)\n",
        "    cx = torch.zeros(batch_size, hidden_size)\n",
        "\n",
        "    hx, cx = lstm(x, hx, cx)\n",
        "    assert hx.detach().allclose(torch.tensor([[0.1784, 0.1784, 0.1784], \n",
        "                                              [0.1784, 0.1784, 0.1784]]), atol=2e-1), \\\n",
        "            f\"Output of the hidden state does not match.\"\n",
        "    assert cx.detach().allclose(torch.tensor([[0.2936, 0.2936, 0.2936], \n",
        "                                              [0.2936, 0.2936, 0.2936]]), atol=2e-1), \\\n",
        "            f\"Output of the cell state does not match.\"\n",
        "\n",
        "    print(\"==LSTM cell test passed!==\")\n",
        "\n",
        "test_lstm()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0DxU-78B33dG"
      },
      "source": [
        "## Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "l0U2s0hux_n6"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(nn.Module):\n",
        "    def __init__(self, input_size=64, hidden_size=64, vocab_size=10000):\n",
        "        super(LanguageModel, self).__init__()\n",
        "        \n",
        "        self.input_layer = nn.Embedding(vocab_size, input_size)\n",
        "        self.hidden_layer = LSTMCell(input_size, hidden_size)\n",
        "        self.output_layer = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, x, hx, cx, predict=False):\n",
        "        \"\"\"\n",
        "        Inputs\n",
        "            input (x): [batch_size]\n",
        "            hidden_state (h_0): [batch_size, hidden_size]\n",
        "            cell_state (c_0): [batch_size, hidden_size]\n",
        "            predict: whether to predict and sample the next word\n",
        "        Outputs\n",
        "            output (ox): [batch_size, hidden_size]\n",
        "            next_hidden_state (h_1): [batch_size, hidden_size]\n",
        "            next_cell_state (c_1): [batch_size, hidden_size]    \n",
        "        \"\"\"\n",
        "        x = self.input_layer(x)\n",
        "        hx, cx = self.hidden_layer(x, hx, cx)\n",
        "        ox = self.output_layer(hx)\n",
        "\n",
        "        if predict == True:\n",
        "            probs = F.softmax(ox, dim=1)\n",
        "            # torch distribution allows sampling operation\n",
        "            # see https://pytorch.org/docs/stable/distributions.html\n",
        "            dist = torch.distributions.Categorical(probs)\n",
        "            ox = dist.sample()\n",
        "\n",
        "        return ox, hx, cx  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G-ZpuMhsbBS8"
      },
      "source": [
        "# 3. Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "y7TY7HmvbRlB"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, \n",
        "                 word2idx, \n",
        "                 idx2word,\n",
        "                 dataloader, \n",
        "                 model, \n",
        "                 criterion,\n",
        "                 optimizer, \n",
        "                 device):\n",
        "        \"\"\"\n",
        "        dataloader: dataloader\n",
        "        model: langauge model\n",
        "        criterion: loss function to evaluate the model (e.g., BCE Loss)\n",
        "        optimizer: optimizer for model\n",
        "        \"\"\"\n",
        "        self.word2idx = word2idx\n",
        "        self.idx2word = idx2word\n",
        "        self.dataloader = dataloader\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        \n",
        "    def train(self, epochs = 1):\n",
        "        self.model.to(self.device)\n",
        "        start_time = time.time()\n",
        "        for epoch in range(epochs):\n",
        "            losses = []\n",
        "            for iter, (x_batch, y_batch) in tqdm.tqdm(enumerate(self.dataloader)):\n",
        "                self.model.train()\n",
        "                \n",
        "                batch_size, max_seq_len = x_batch.shape\n",
        "                x_batch = x_batch.to(self.device)\n",
        "                y_batch = y_batch.to(self.device)\n",
        "\n",
        "                # initial hidden-states\n",
        "                hx = torch.zeros(batch_size, hidden_size).to(self.device)\n",
        "                cx = torch.zeros(batch_size, hidden_size).to(self.device)\n",
        "\n",
        "                # Implement LSTM operation\n",
        "                ox_batch = []\n",
        "                # Get output logits for each time sequence and append to the list, ox_batch\n",
        "                # YOUR CODE HERE (~ 4 lines)\n",
        "                for s_idx in range(max_seq_len):\n",
        "                    x = x_batch[:, s_idx]\n",
        "                    ox, hx, cx = self.model(x, hx, cx)\n",
        "                    ox_batch.append(ox)\n",
        "                # outputs are ordered by the time sequence\n",
        "                ox_batch = torch.cat(ox_batch).reshape(max_seq_len, batch_size, -1)\n",
        "                ox_batch = ox_batch.permute(1,0,2).reshape(batch_size*max_seq_len, -1)\n",
        "                y_batch = y_batch.reshape(-1)\n",
        "\n",
        "                self.model.zero_grad()\n",
        "                loss = self.criterion(ox_batch, y_batch)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                losses.append(loss.item())\n",
        "\n",
        "            end_time = time.time() - start_time\n",
        "            end_time = str(datetime.timedelta(seconds=end_time))[:-7]\n",
        "            print('Time [%s], Epoch [%d/%d], loss: %.4f'\n",
        "                  % (end_time, epoch+1, epochs, np.mean(losses)))\n",
        "            if epoch % 5 == 0:\n",
        "                generated_sentences = self.test()\n",
        "                print('[Generated Sentences]')\n",
        "                for sentence in generated_sentences:\n",
        "                    print(sentence)\n",
        "            \n",
        "    def test(self):\n",
        "        # Test model to genereate the sentences\n",
        "        self.model.eval()\n",
        "        num_sentence = 5\n",
        "        max_seq_len = 50\n",
        "\n",
        "        # initial hidden-states\n",
        "        outs = []\n",
        "        x = torch.randint(0, 10000, (num_sentence,)).to(self.device)\n",
        "        hx = torch.zeros(num_sentence, hidden_size).to(self.device)\n",
        "        cx = torch.zeros(num_sentence, hidden_size).to(self.device)\n",
        "\n",
        "        outs.append(x)\n",
        "        with torch.no_grad():\n",
        "            for s_idx in range(max_seq_len-1):\n",
        "                x, hx, cx = self.model(x, hx, cx, predict=True)\n",
        "                outs.append(x)\n",
        "        outs = torch.cat(outs).reshape(max_seq_len, num_sentence)\n",
        "        outs = outs.permute(1, 0)\n",
        "        outs = outs.detach().cpu().numpy()\n",
        "\n",
        "        sentences = []\n",
        "        for out in outs:\n",
        "            sentence = []\n",
        "            for token_idx in out:\n",
        "                word = self.idx2word[token_idx]\n",
        "                sentence.append(word)\n",
        "            sentences.append(sentence)\n",
        "       \n",
        "        return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1EE9KDvyeeF",
        "outputId": "1a4f9559-da93-45d1-f0f5-c2a34b7e7b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([64, 50])\n",
            "torch.Size([20, 50])\n"
          ]
        }
      ],
      "source": [
        "for iter,(x_batch,y_batch) in (enumerate(dataloader)):\n",
        "    print(x_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgEJv1vWqNkS",
        "outputId": "fc317b54-3bdf-4d66-df09-1d4ce8e2dae0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:21,  7.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:00:21], Epoch [1/50], loss: 6.1041\n",
            "[Generated Sentences]\n",
            "['paying', 'plight', 'last', 'mail', 'junk', 'bonds', 'changed', 'h&r', 'him', 'as', 'new', 'products', 'from', 'current', 'activity', 'music', 'less', 'than', 'the', 'no.', 'until', 'this', 'month', 'when', 'he', 'added', 'the', 'end', 'on', '<unk>', 'the', 'supreme', 'department', \"'s\", 'restored', '<unk>', 'no', 'tourism', 'nasty', 'making', 'it', \"'s\", 'writers', 'on', 'an', 'core', 'total', 'river', 'sales', 'trillion']\n",
            "['invested', 'courtaulds', 'the', 'beverly', 'one', 'day', 'this', 'year', 'never', 'consistently', 'not', 'disclosed', 'available', 'of', 'mr.', 'hastings', 'in', 'philadelphia', 'dropped', 'N', 'out', 'in', 'legislation', 'to', 'meet', 'controlled', 'to', 'accept', 'the', 'red', 'ford', 'transaction', 'contracts', 'resources', 'sen.', 'james', 'entry', 'nearly', 'futures', 'bags', 'total', 'investment', 'N', 'billion', 'yen', '$', 'N', 'million', 'or', 'N']\n",
            "['notorious', 'social', 'wrongdoing', 'the', 'software', 'printing', 'convenience', 'security', 'boren', 'says', 'an', 'N', 'billion', '<unk>', 'during', 'the', 'accord', 'not', 'directs', 'promote', 'loan', 'pension', 'and', 'increases', 'on', 'show', 'the', '<unk>', 'lighting', 'county', 'of', 'parliament', 'to', 'find', 'the', 'appreciation', 'between', 'the', 'current', 'criticism', 'the', 'associations', 'will', 'serve', 'suggested', 'in', '<unk>', 'now', 'were', 'changed']\n",
            "['former', 'information', 'selling', 'the', 'poor', 'arrived', 'to', 'retrieve', 'fears', 'to', 'be', 'respected', '<unk>', 'by', 'figures', 'and', '<unk>', 'into', 'more', 'than', 'the', 'other', 'rights', 'along', 'provides', '<unk>', 'an', 'opportunity', 'to', '<unk>', 'to', 'finance', 'blueprint', 'practical', 'software', 'announced', 'the', 'house', 'since', 'into', 'guy', 'total', 'instead', 'of', 'N', 'in', 'this', 'year', 'to', 'meet']\n",
            "['respectively', 'studies', 'that', 'makes', 'its', '#', 'N', 'rubles', 'on', 'the', 'success', 'increasingly', 'profit', 'of', 'whom', '<unk>', 'though', 'john', 'boston', \"'s\", 'financial', 'planning', '<unk>', '<unk>', '<unk>', 'said', 'that', 'detected', 'diamond', 'up', 'little', 'not', 'to', 'expand', 'some', 'last', 'outside', 'debt', 'in', 'the', 'market', 'prompted', 'the', 'national', '<unk>', 'shipments', 'of', 'pounds', 'directly', 'research']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:00:36], Epoch [2/50], loss: 5.2393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:16, 10.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:00:53], Epoch [3/50], loss: 4.9173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:01:08], Epoch [4/50], loss: 4.7097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:01:24], Epoch [5/50], loss: 4.5509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:01:39], Epoch [6/50], loss: 4.4211\n",
            "[Generated Sentences]\n",
            "['design', 'korea', 'and', 'exchange', 'commission', 'will', 'help', 'losing', 'revenue', 'in', '<unk>', 'chancery', 'business', 'products', 'to', 'be', 'dominated', 'by', 'the', 'international', 'airport', '<unk>', 'institute', 'a', 'factor', 'of', '<unk>', '<unk>', 'space', 'probe', 'some', 'tricky', 'bench', 'may', 'seek', 'to', 'carry', 'some', '<unk>', 'in', 'a', 'former', 'european', 'community', 'research', 'firm', 'said', 'extended', 'construction', 'spending']\n",
            "['skeptical', 'south', 'korean', 'foreign', 'investment', 'trust', 'fell', 'N', 'cents', 'to', '$', 'N', 'billion', 'to', '$', 'N', 'billion', 'up', 'N', 'cents', 'a', 'share', 'compared', 'with', 'its', 'first', 'boston', 'examiner', 'essential', 'to', '<unk>', 'advertising', 'and', 'miller', 'other', 'categories', \"'s\", 'computer', 'processing', 'computer', 'to', 'sell', 'frankfurt', 'markets', 'said', 'the', 'weakening', 'is', 'a', 'charge']\n",
            "['leave', 'telephone', 'projects', 'defense', 'minister', 'often', 'opponents', 'older', 'with', 'a', '<unk>', '<unk>', 'but', 'the', 'economic', 'crisis', 'in', 'the', 'community', 'bill', 'is', 'expected', 'to', 'be', 'spent', 'from', 'large', 'regions', 'of', 'federal', 'policy', 'and', 'fruit', '<unk>', 'than', 'in', 'productivity', 'that', 'they', 'usually', 'happened', 'around', 'against', 'them', 'to', '<unk>', 'to', '<unk>', 'fluctuations', 'and']\n",
            "['streamline', 'tailspin', 'assumed', 'assassinations', 'now', 'said', 'the', 'carrier', 'will', 'be', 'delivered', 'only', 'marginally', 'expensive', 'to', 'purchase', 'N', 'N', 'and', 'N', 'cents', 'after', 'morgan', 'stanley', '&', 'co.', 'purchased', 'a', 'N', 'N', 'rating', 'at', 'goldman', 'sachs', '&', 'co.', 'an', 'investment', 'group', 'of', '<unk>', 'earlier', 'this', 'year', 'primarily', 'a.', '<unk>', 'a', 'subsidiary', 'to']\n",
            "['accelerate', 'day', 'already', 'stopped', 'a', 'new', '<unk>', 'courtroom', 'since', 'N', 'street', 'in', 'which', 'the', 'futures', 'market', 'declines', 'when', 'damage', 'that', 'blocks', 'the', '<unk>', '<unk>', 'to', 'badly', 'themselves', 'as', 'a', 'professional', 'investor', 'who', 'came', 'in', 'auto', 'rules', 'to', 'push', 'natural', 'gas', 'companies', 'next', 'year', 'it', 'would', 'create', 'rolling', 'at', 'N', 'times']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:01:55], Epoch [7/50], loss: 4.3145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:02:11], Epoch [8/50], loss: 4.2224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:02:26], Epoch [9/50], loss: 4.1427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:02:42], Epoch [10/50], loss: 4.0706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:02:57], Epoch [11/50], loss: 4.0093\n",
            "[Generated Sentences]\n",
            "['green', 'teams', 'the', 'marketplace', 'i', 'believe', 'there', 'was', 'the', '<unk>', 'of', 'my', 'own', 'with', 'schools', 'while', 'cycling', 'complained', 'that', 'they', \"'ve\", 'been', 'confiscated', 'or', 'more', '<unk>', 'than', 'california', \"'s\", 'play', 'rather', 'than', 'blacks', 'they', 'discover', 'that', 'we', 'need', 'any', 'settlement', 'it', 'was', \"n't\", \"n't\", 'in', 'returns', 'to', 'their', 'own', 'quarterly']\n",
            "['summit', 'offset', 'yesterday', 'discontinued', 'chemicals', 'projects', 'that', 'were', 'continuing', 'slightly', 'lower', 'at', 'N', 'p.m.', 'est', 'on', 'a', 'proving', 'to', 'do', 'differently', 'on', 'the', 'new', 'york', 'stock', 'exchange', 'the', 'industry', 'business', 'of', 'ual', 'mining', 'the', 'u.k.', 'and', 'at', '$', 'N', 'range', 'with', 'N', 'N', 'off', 'N', 'almost', 'N', 'million', 'shares', 'outstanding']\n",
            "['corporations', 'at', 'home', 'shopping', 'and', 'permitting', 'economic', 'indicators', 'practices', 'vary', 'from', 'tourism', 'and', 'broadly', 'complex', 'and', 'sophisticated', 'tests', 'to', 'reduce', 'the', 'couple', \"'s\", '<unk>', '<unk>', '<unk>', 'are', 'seeking', 'to', 'devote', 'ian', 'statistics', 'operating', 'agency', 'facilities', 'and', 'dropped', 'N', 'N', 'to', 'N', 'N', 'in', 'september', 'to', 'N', 'yen', 'in', 'the', 'year-earlier']\n",
            "['gestures', 'fell', 'N', 'N', 'to', 'N', 'N', 'and', 'N', 'yen', 'up', 'from', 'N', 'yen', 'down', 'from', 'net', 'cash', 'from', 'a', 'loss', 'for', 'september', 'new', 'york', 'investor', 'marvin', 'and', 'atlantic', 'richfield', 'co.', 'billing', '<unk>', 'shares', 'selling', 'coal', 'and', 'financial', 'services', 'division', 'and', 'overall', 'write-downs', '<unk>', 'by', 'three', 'million', 'shares', 'at', 'lower']\n",
            "['sacramento', 'started', 'at', 'first', 'boston', 'corp', 'a', 'chain', \"'s\", 'eighth', 'quarter', 'despite', 'a', 'very', 'bid', 'for', 'the', 'world', 'thrift', 'has', 'N', 'abroad', 'due', 'in', 'the', 'missouri', 'assembly', 'meanwhile', 'closed', 'at', 'candlestick', 'park', 'involving', 'electricity', 'programs', 'in', 'the', 'past', 'spring', 'after', 'monday', \"'s\", 'initial', 'plunge', 'in', 'the', 'quarter', \"'s\", 'rapid', 'pace']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:03:13], Epoch [12/50], loss: 3.9534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:03:28], Epoch [13/50], loss: 3.9003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:16, 10.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:03:44], Epoch [14/50], loss: 3.8555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:04:00], Epoch [15/50], loss: 3.8137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:04:15], Epoch [16/50], loss: 3.7761\n",
            "[Generated Sentences]\n",
            "['l.p.', 'motors', 'corp.', 'placed', 'as', 'a', '<unk>', 'assistant', 'vice', 'president', 'of', 'circus', 'enterprises', 'for', 'the', 'sight', 'soon', 'discover', 'no', 'federal', 'regulations', 'will', 'be', 'followed', 'until', 'the', 'irs', 'may', 'be', '<unk>', 'anyway', 'anything', 'wants', 'just', 'about', 'N', 'N', 'of', 'bonds', 'due', 'in', 'N', 'hours', 'of', 'series', 'the', '<unk>', 'radar', 'plant', 'and']\n",
            "['transatlantic', 'termed', 'interviews', 'against', 'it', 'with', 'the', 'additional', 'liquidity', 'will', 'probably', 'determine', 'if', '<unk>', 'has', 'big', 'commitments', 'a', 'long', 'way', 'through', '<unk>', 'that', 'goes', 'on', 'his', 'desk', \"'s\", 'members', 'yesterday', 'so', '<unk>', 'a', 'lot', 'of', 'casinos', 'bonds', 'took', 'a', 'setback', 'for', 'retiring', 'and', 'filed', 'against', 'a', 'boat', 'in', 'federal', 'court']\n",
            "['low-cost', 'cardiovascular', 'who', 'used', 'a', 'tax', 'cut', 'from', 'diamond', 'creek', \"'s\", '<unk>', 'a', '<unk>', 'halt', 'that', 'the', 'so-called', 'section', 'such', 'as', 'cheap', 'leadership', 'operated', 'at', 'the', 'firm', 'he', 'wants', 'before', 'a', '<unk>', 'put', 'is', 'not', 'acting', 'as', 'workers', 'as', 'well', 'as', 'hospitals', 'in', 'hospitals', 'and', '<unk>', '<unk>', 'ag', 'plans', 'in']\n",
            "['began', 'in', 'july', 'N', 'the', 'failed', 'ashland', 'gained', 'N', 'to', 'N', 'N', 'down', 'from', 'N', 'N', 'and', 'N', 'N', 'two', 'months', 'N', '<unk>', 'gains', 'and', 'N', 'japanese', 'households', 'exceeded', 'additional', 'shares', 'they', '<unk>', 'out', 'the', 'dividend', 'payment', 'by', 'dow', 'jones', 'which', 'represents', 'the', '<unk>', 'for', 'the', 'country', 'to', 'keep', 'the']\n",
            "['provisional', 'earnings', 'offset', 'a', 'one-time', 'gain', 'of', '$', 'N', 'million', 'in', 'the', 'third', 'quarter', 'and', 'held', 'a', 'N', 'N', 'higher', 'price', 'of', 'the', 'company', \"'s\", 'stock', 'which', 'is', 'low', 'a', 'small', 'guarantee', 'of', 'beef', 'from', 'insurance', 'brokers', 'peter', 'dapuzzo', 'head', 'of', 'saatchi', \"'s\", 'backer', 'spielvogel', '<unk>', 'the', 'former', 'bank', 'executive']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:04:31], Epoch [17/50], loss: 3.7386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:04:47], Epoch [18/50], loss: 3.7065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:05:02], Epoch [19/50], loss: 3.6777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:05:18], Epoch [20/50], loss: 3.6505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:05:34], Epoch [21/50], loss: 3.6238\n",
            "[Generated Sentences]\n",
            "['kkr', 'had', 'five', 'radio', 'in', 'its', '<unk>', 'union', 'owning', 'the', 'financial', 'markets', 'today', 'took', 'place', 'in', 'social', 'buying', 'deregulation', 'in', 'a', '<unk>', 'scale', 'this', 'next', 'year', 'mr.', 'wathen', \"'s\", 'articles', 'of', 'workers', '<unk>', 'and', 'fish', 'in', 'economic', 'affairs', 'and', 'the', 'balance', 'of', 'workers', 'from', 'these', 'reasons', 'i', 'believe', 'i', 'want']\n",
            "['referred', 'cowboys', 'as', 'an', 'accord', 'with', 'jaguar', 'about', 'half', 'of', 'N', 'rather', 'an', 'arms-control', 'spokeswoman', 'for', 'europe', 'in', 'its', 'history', 'in', 'a', 'house-senate', 'conference', 'on', 'the', 'bottom', 'end', 'because', 'gene', 'is', 'often', 'difficult', 'in', 'the', 'field', 'immediately', 'wider', '<unk>', 'passengers', 'onto', 'colombian', 'treasury', 'bill', 'toward', 'which', 'N', 'N', 'of', 'the']\n",
            "['gerrymandering', 'from', 'eduard', 'shevardnadze', '<unk>', 'the', 'effectiveness', 'of', 'the', '1980s', 'i', 'took', 'christian', 'leader', 'and', 'the', 'leveraged', 'team', 'ultimately', \"'d\", 'want', 'to', 'speed', 'things', 'precisely', 'and', 'gm', 'looks', 'like', 'to', 'appear', 'in', 'most', 'schools', 'to', 'trade', 'out', 'what', 'for', 'public', 'lost', 'on', '<unk>', 'where', 'the', '<unk>', '<unk>', 'produced', 'much', 'of']\n",
            "['regulate', 'overdue', 'renaissance', \"'s\", 'proposal', 'aimed', 'at', 'its', 'highly', 'successful', 'with', 'hazardous', 'chemicals', 'and', '<unk>', 'about', '$', 'N', '<unk>', 'for', 'N', 'N', 'in', 'the', 'corresponding', 'period', 'last', 'week', \"'s\", 'earthquake', 'and', 'grocery', 'stores', 'but', 'monday', \"'s\", '<unk>', 'losses', 'were', 'disclosed', 'in', 'the', 'annual', 'net', 'cash', 'market', 'based', 'on', 'railroad', 'annual']\n",
            "['proposition', 'frightened', 'scenes', 'breeden', 'all', 'very', '<unk>', 'sell', 'on', 'monday', 'than', '$', 'even', 'but', 'because', 'jaguar', 'with', 'no', '<unk>', 'stocks', 'they', 'obtain', 'restoration', 'of', 'differences', 'with', 'the', 'way', 'that', 'not', 'been', 'he', 'says', '<unk>', '<unk>', 'an', 'analyst', 'at', 'manufacturer', 'negotiations', 'for', 'republicans', 'energy', 'home', 'or', '<unk>', 'gold', 'rose', 'N', 'N']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:05:49], Epoch [22/50], loss: 3.5993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:06:05], Epoch [23/50], loss: 3.5767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:06:21], Epoch [24/50], loss: 3.5552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:06:36], Epoch [25/50], loss: 3.5368\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:06:52], Epoch [26/50], loss: 3.5185\n",
            "[Generated Sentences]\n",
            "['impeachment', 'viewpoint', 'yankee', 'interpreted', 'the', 'wall', 'street', 'firms', 'are', 'already', 'highly', 'declining', 'than', 'N', 'N', 'of', 'turner', 'broadcasting', 'of', 'the', 'philippines', 'fled', 'the', 'market', 'or', 'about', 'N', 'newsweek', '<unk>', 'texas', 'or', 'new', 'homes', '<unk>', 'from', 'the', 'atlantic', 'coast', 'design', 'and', 'teaching', 'methods', 'and', 'circus', '<unk>', '<unk>', 'like', 'earthquakes', 'here', 'in']\n",
            "['day', 'could', 'enjoy', 'action', 'to', 'focus', 'on', 'human', 'services', 'to', 'sell', 'through', 'ual', 'radio', 'in', 'federal', 'aid', 'that', 'would', 'otherwise', 'have', 'on', 'a', 'larger', 'basis', 'in', 'areas', 'with', 'their', 'profits', 'said', 'james', 'h.', 'miller', 'gold', 'manager', 'of', 'japan', \"'s\", 'largest', 'accounts', 'through', 'its', 'suit', 'against', 'the', 'rebel', 'units', 'and', 'a']\n",
            "['bankruptcy-law', 'medium-sized', 'stop', 'fisher', 'loan', 'documents', 'filed', 'on', 'official', 'minister', 'tv', 'gillette', 'said', 'it', 'had', 'repeatedly', 'proved', 'that', 'the', 'N', 'periods', 'in', 'the', 'previous', 'popularity', 'and', 'thus', 'village', 'has', 'interests', 'in', 'new', 'york', 'now', 'ibm', \"'s\", 'tumble', 'N', 'times', 'N', 'N', 'at', 'july', 'N', 'N', 'in', 'the', 'new', 'york', 'the']\n",
            "['foothills', 'had', 'retired', 'candidates', 'to', 'sell', 'the', 'group', 'of', 'the', 'two', '<unk>', 'fla.', 'N', 'N', 'of', 'the', 'original', 'exchange', 'time', 'a', 'group', 'asked', 'earnings', 'and', 'lower', 'shipments', 'of', 'a', 'N', 'N', 'price', 'drop', 'in', 'the', 'performance', 'of', '<unk>', 'advertising', 'and', '<unk>', 'would', \"n't\", 'comment', 'on', 'japan', 'of', 'eastern', \"'s\", 'directors']\n",
            "['refcorp', 'budget', 'outstanding', 'said', 'employees', 'have', 'been', 'some', 'new', 'tenants', 'to', 'try', 'to', 'avoid', 'specific', 'values', 'police', 'to', 'politicians', 'public', 'relations', 'with', 'buick', 'regulators', '<unk>', 'to', 'market', 'direct', 'mail', 'rooms', 'as', 'the', 'consequences', 'of', 'his', 'accelerating', 'yard', 'the', 'carrier', 'says', 'van', '<unk>', 'N', '<unk>', 'in', 'spite', 'of', 'the', 'daughters', \"'\"]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:07:08], Epoch [27/50], loss: 3.5014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:07:23], Epoch [28/50], loss: 3.4847\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:07:39], Epoch [29/50], loss: 3.4714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:07:55], Epoch [30/50], loss: 3.4566\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:08:11], Epoch [31/50], loss: 3.4425\n",
            "[Generated Sentences]\n",
            "['estimated', 'late', 'friday', 'and', 'when', 'its', 'businesses', 'and', 'the', 'restructuring', 'could', 'invest', 'big', 'institutional', 'investors', 'association', 'or', 'adequate', 'on', 'its', 'borrowings', 'has', 'outperformed', 'nearly', 'did', \"n't\", 'an', 'additional', 'N', 'three', 'months', 'bank', 'operating', 'index', 'and', 'a', 'second', 'quarterly', 'report', 'by', 'the', 'recent', 'price', 'of', 'its', 'N', 'securities', 'act', 'rated', 'single-a-1']\n",
            "['bnl', 'has', 'N', 'million', 'common', 'shares', 'later', 'suspended', 'compared', 'with', 'a$', 'N', 'billion', 'in', 'assets', 'and', 'large', 'corporations', 'but', 'with', 'real-estate', 'sales', 'and', 'general', 'dynamics', 'corp.', 'posted', 'lower', 'earnings', 'for', '<unk>', \"'s\", 'life', 'of', 'the', '<unk>', 'of', 'a', 'new', 'business', 'which', 'separately', 'city', 'high-risk', 'transactions', 'valued', 'at', 'more', 'than', 'half']\n",
            "['constituency', 'boards', 'of', 'N', 'million', 'shares', 'will', 'be', 'converted', 'into', 'its', '<unk>', 'product', 'line', 'and', 'will', 'meet', 'the', 'recall', 'that', 'in', 'preferred', 'stock', 'closed', 'narrowly', 'traded', 'for', 'november', 'delivery', 'or', 'N', 'cents', 'a', 'share', 'down', 'N', 'N', 'from', 'N', 'N', 'on', 'sales', 'statistics', 'canada', 'and', 'marshall', 'field', 'the', 'luxury', 'auto']\n",
            "['spots', 'pit', 'humana', 'has', 'soon', 'buy', 'for', 'new', 'plant', 'which', 'in', 'the', 'industry', 'analysts', 'said', 'they', 'have', 'experienced', 'another', '<unk>', 'segment', 'in', 'tokyo', 'and', 'a', 'national', 'majority', 'of', 'enfield', 'without', 'full', 'operation', 'that', 'had', 'won', 'in', 'N', 'and', 'they', 'can', 'resolve', 'reform', 'into', 'buying', 'and', 'forgotten', 'by', 'both', 'cities', 'mounted']\n",
            "['training', 'presumed', 'builders', 'says', 'can', 'wide', '<unk>', 'this', 'cool', 'to', 'far', 'more', 'customers', \"'\", 'fundamental', 'back', 'actions', 'replaced', 'what', 'mr.', 'roberts', 'is', 'about', 'a', '<unk>', 'of', 'legal', 'ethics', 'funds', 'by', 'floating', 'criticism', 'from', 'higher', 'liabilities', 'by', 'reported', 'a', 'few', 'pennies', 'from', 'now', 'report', 'open', 'to', 'give', 'tandy', 'most', 'well-known', 'reports']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:08:26], Epoch [32/50], loss: 3.4309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:08:42], Epoch [33/50], loss: 3.4205\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:08:57], Epoch [34/50], loss: 3.4115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:09:13], Epoch [35/50], loss: 3.3955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:09:29], Epoch [36/50], loss: 3.3887\n",
            "[Generated Sentences]\n",
            "['episode', 'sometimes', 'former', '<unk>', 'all', 'has', 'forecast', 'a', 'surprise', 'washington', 'work', 'focusing', 'on', 'image', 'but', '<unk>', 'affairs', 'who', 'have', 'faced', 'with', 'many', 'employers', 'grant', 'such', 'that', 'post', 'and', 'said', 'a', 'group', 'of', 'chrysler', 'and', 'international', 'coal', 'and', 'others', 'are', 'expected', 'to', 'raise', 'cash', 'for', 'this', 'year', 'and', 'by', 'payment', 'and']\n",
            "['corporations', 'have', 'been', 'the', 'right', 'to', 'buy', 'a', 'stake', 'in', 'south', 'which', 'individual', 'lenders', 'and', 'more', 'it', 'away', 'despite', 'the', 'disk-drive', 'maker', 'annual', 'sales', 'of', 'about', '$', 'N', 'million', '<unk>', 'and', 'will', 'help', 'boost', 'its', 'clients', 'including', 'a', 'package', 'of', 'a', '<unk>', 'suit', 'and', 'a', 'host', 'of', '<unk>', '<unk>', 'computers']\n",
            "['consequence', 'spent', 'mostly', 'the', 'pound', 'before', 'four', 'percentage', 'point', 'higher', 'than', 'usual', 'sales', 'expectations', 'of', 'strong', 'growth', 'in', 'pulp', 'if', 'a', 'surprising', 'surplus', 'they', 'designed', 'to', 'sell', 'new', 'york', 'bonds', 'that', 'were', 'less', 'than', 'N', 'N', 'meaning', 'between', 'N', 'N', 'more', 'than', '$', 'N', 'per', 'worker', \"'s\", 'share', 'price', 'on']\n",
            "['upper', 'apple', 'attorney', \"'s\", 'church', 'was', 'accompanied', 'by', 'a', 'negative', 'forecast', 'on', 'their', 'own', '<unk>', 'positions', 'sold', 'by', 'N', 'N', 'in', 'N', 'and', 'trading', 'after', 'bear', 'stearns', 'said', 'interest', 'rates', 'move', 'in', 'its', 'contracts', 'with', 'enfield', 'seeks', '<unk>', 'to', 'buy', 'oil', 'and', 'production', 'of', 'its', 'new', 'corporate', 'debt', 'including', 'minpeco']\n",
            "['troubled', 'concerns', 'handles', 'the', 'federal', 'examination', 'was', 'the', 'main', 'to', 'take', 'to', 'hear', 'the', 'list', 'of', 'stocks', 'later', 'than', 'other', '<unk>', 'nations', 'but', 'in', 'the', 'week', 'that', 'it', \"'s\", 'recent', 'weakness', 'in', 'the', 'stock', 'market', 'as', 'change', 'what', 'signs', 'of', 'stocks', 'that', 'fears', 'was', 'too', 'narrow', 'after', 'watching', 'that', 'are']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:09:44], Epoch [37/50], loss: 3.3802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:10:00], Epoch [38/50], loss: 3.3736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:10:16], Epoch [39/50], loss: 3.3652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:10:31], Epoch [40/50], loss: 3.3580\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:10:47], Epoch [41/50], loss: 3.3502\n",
            "[Generated Sentences]\n",
            "['obtain', 'a', 'series', 'of', '<unk>', 'cos.', 'the', 'president', 'was', 'appointed', 'in', 'response', 'to', 'its', 'present', 'form', 'of', '<unk>', 'magazine', '<unk>', 'and', '<unk>', 'have', 'increased', 'rights', 'to', 'win', 'nine', 'chips', 'from', 'commercial', 'banks', 'in', 'the', 'u.s.', 'ruling', 'the', 'client', \"'s\", 'deputy', 'mayor', 'and', 'dozens', 'of', '<unk>', \"'s\", '<unk>', '<unk>', 'in', 'the']\n",
            "['callable', 'from', 'exchange', 'for', 'one-time', 'gains', 'for', 'the', 'right', 'offering', 'of', 'millions', 'of', 'dollars', 'of', 'up', 'N', 'N', 'to', 'N', 'and', 'other', '<unk>', 'are', 'almost', 'a', '<unk>', 'picture', 'still', 'year', 'in', 'late', 'august', 'contracts', 'for', 'a', 'few', 'years', 'due', 'as', 'inevitable', 'as', 'being', 'overcapacity', 'on', 'more', 'than', 'N', 'N', 'a']\n",
            "['thing', 'racketeering', \"'s\", 'profits', 'go', 'into', 'nature', 'significant', 'changes', 'in', 'their', 'games', 'perhaps', 'the', 'stock', 'market', \"'s\", 'jet', 'planes', 'and', 'renault', \"'s\", 'unemployment', 'ranks', 'a', 'college', 'degree', 'of', 'how', 'much', 'of', 'the', 'entire', 'business', 'world', 'limited', 'to', 'try', 'to', 'aid', 'nicaragua', \"'s\", 'cars', 'they', 'needed', 'to', 'take', 'place', 'pieces', 'that']\n",
            "['receiver', 'revoke', 'efficiency', 'funds', \"'\", 'high', 'ground', 'and', 'which', 'reduce', 'large', 'data', 'contraceptive', 'devices', 'such', 'as', '<unk>', 'management', 'and', 'corporate', 'ties', 'in', 'front', 'police', 'and', 'political', 'solutions', 'research', 'said', 'alan', 'cranston', 'probably', 'had', 'a', 'drink', '<unk>', 'to', 'ensure', 'a', '<unk>', 'response', 'to', 'the', 'record', 'and', 'preventing', 'the', 'city', \"'s\", '<unk>']\n",
            "['eagerness', 'chance', 'would', 'have', 'to', 'go', 'when', 'they', 'do', 'to', 'think', 'about', 'serious', 'property', 'simply', '<unk>', 'momentum', 'is', 'like', 'the', 'futures', 'and', 'september', 'futures', 'trading', 'institutions', 'can', 'only', 'N', 'N', 'of', 'the', 'u.s.', 'public', \"'s\", 'common', 'stock', 'price', 'and', 'what', 'amounted', 'to', 'a', 'committee', 'per', 'ruling', 'clears', 'from', 'the', 'N']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:11:02], Epoch [42/50], loss: 3.3434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:16, 10.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:11:18], Epoch [43/50], loss: 3.3366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:11:34], Epoch [44/50], loss: 3.3316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:11:50], Epoch [45/50], loss: 3.3249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:12:05], Epoch [46/50], loss: 3.3184\n",
            "[Generated Sentences]\n",
            "['exporters', 'assembled', 'memories', 'the', 'chance', 'in', 'new', 'york', \"'s\", 'franchisees', 'go', 'up', 'and', 'what', 'is', 'necessary', 'to', 'gauge', 'how', 'long', 'the', 'proposed', 'illustrates', 'the', 'real', 'jet', '<unk>', 'role', 'of', 'wealthy', '<unk>', 'de', '<unk>', 'mr.', '<unk>', 'about', 'N', 'words', 'indicates', 'that', 'the', 'government', \"'s\", 'ongoing', 'program', 'generally', 'smaller', 'financial', 'stock', 'index']\n",
            "['proponents', 'ahead', 'of', 'the', 'funds', 'rate', 'to', 'N', 'office', 'are', 'callable', 'the', 'gain', 'since', 'a', 'high', 'market', 'for', 'a', 'comfortable', 'form', 'of', 'repeated', 'renaissance', \"'s\", 'earthquake', 'claimed', 'relative', 'in', 'the', 'aftermath', 'of', 'many', 'reports', 'N', 'times', 'that', 'federal', 'courts', 'had', \"n't\", 'give', 'the', 'white', 'house', '<unk>', 'in', 'its', 'cases', 'a']\n",
            "['superconductor', 'luzon', 'evaluating', 'saatchi', 'flooded', 'despite', 'becoming', 'the', 'virginia', 'idea', 'the', 'actor', 'wall', 'street', \"'s\", 'paper', 'and', 'british', 'arm', 'hopes', 'for', 'financial', 'alternatives', 'with', 'major', 'shareholders', 'to', 'determine', 'expectations', 'say', 'the', 'company', 'has', 'a', 'facsimile', 'edition', 'to', 'purchase', 'heavy', 'package', 'for', 'that', 'fiscal', 'third-quarter', 'earnings', 'declined', 'to', '$', 'N', 'million']\n",
            "['fortune', 'that', 'will', 'be', 'required', 'because', 'interest', 'rates', 'are', \"n't\", 'necessarily', 'by', '<unk>', 'for', 'the', 'findings', 'of', 'the', 'drug', 'market', 'says', 'joseph', '<unk>', 'analyst', 'with', 'computer', 'systems', '<unk>', 'as', 'directors', 'of', 'hees', 'international', 'bancorp', 'inc.', 'analyst', 'at', 'london', \"'s\", 'board', 'said', 'it', 'had', \"n't\", 'yet', 'been', '<unk>', 'since', 'ual', 'corp.']\n",
            "['china', 'since', '<unk>', 'software', 'products', 'will', 'help', 'edge', 'back', 'most', 'of', 'all', 'per-share', 'earnings', 'for', 'the', 'company', 'said', 'is', 'new', 'orleans', 'boston', 'made', 'a', 'special', 'b.a.t', 'yesterday', 'to', 'help', 'fend', 'off', 'paribas', '<unk>', '<unk>', 'in', 'costa', 'rica', 'marking', 'on', 'the', '<unk>', 'drug', 'created', 'by', 'and', 'after', 'his', 'career', 'on', 'the']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:12:21], Epoch [47/50], loss: 3.3125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:12:37], Epoch [48/50], loss: 3.3095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:12:52], Epoch [49/50], loss: 3.3062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [00:15, 10.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time [0:13:08], Epoch [50/50], loss: 3.3020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "lr = 1e-2\n",
        "input_size = 128\n",
        "hidden_size = 128\n",
        "batch_size = 256\n",
        "\n",
        "dataset = LMDataset(tokens)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "model = LanguageModel(input_size=input_size, hidden_size=hidden_size)\n",
        "# NOTE: Use ignore_index to ignore the loss from predicting the <PAD> token\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "device = torch.device('cuda')\n",
        "\n",
        "trainer = Trainer(word2idx = word2idx,\n",
        "                  idx2word = idx2word,\n",
        "                  dataloader=dataloader, \n",
        "                  model = model,\n",
        "                  criterion=criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device=device)\n",
        "\n",
        "trainer.train(epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ua-_6W2a5Lt"
      },
      "source": [
        "# References\n",
        "\n",
        "1. https://github.com/pytorch/examples/tree/master/word_language_model\n",
        "2. https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/language_model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
