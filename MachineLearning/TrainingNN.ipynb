{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jR26RFkwXtvi"
      },
      "source": [
        "# **Training Neural Network**\n",
        "2023-01-30\n",
        "\n",
        "1. Prerequisite\n",
        "2. Activation\n",
        "3. Optimizer\n",
        "4. Regularization\n",
        "5. FC vs Conv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp3f6JjmmlC3"
      },
      "source": [
        "# 1. Prerequisite\n",
        "\n",
        "Mnist dataset에 대해서 DataLoader와 Trainer class를 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crVJ36mMlaXP"
      },
      "source": [
        "\n",
        "\n",
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqVdEuPQzMAH",
        "outputId": "e5bd1409-06e1-4a06-8fd3-966bfe1736dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.1+cu116\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2o3-HPdHLZma"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMkIJgfEl9kD"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCnmrA9ltYs0",
        "outputId": "df435d6f-4f77-464a-e1a8-07ed2fa2fff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(70000, 784)\n",
            "(70000,)\n"
          ]
        }
      ],
      "source": [
        "mnist = fetch_openml('mnist_784', cache=False)\n",
        "X = mnist.data.astype('float32').values\n",
        "y = mnist.target.astype('int64').values\n",
        "X /= 255.0\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-u3e9taDjT"
      },
      "source": [
        "## Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HWWRcNjaLDi",
        "outputId": "a706eb24-bbb9-4c42-cdff-a8de32e1e39a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(56000, 784)\n",
            "(56000,)\n",
            "(14000, 784)\n",
            "(14000,)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYnvqbdijWUQ"
      },
      "source": [
        "## Pytorch Dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ypqp7zA-xRlB"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        super(CustomDataset, self).__init__()\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.X[index]\n",
        "        y = self.y[index]\n",
        "        x = torch.from_numpy(x).float()\n",
        "        y = torch.from_numpy(np.array(y)).long()\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTr4OWatzmaU",
        "outputId": "a158fb06-663d-4b11-adc0-810efb018cb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "56000\n",
            "(56000, 784)\n",
            "14000\n",
            "(14000, 784)\n"
          ]
        }
      ],
      "source": [
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(train_dataset.X.shape)\n",
        "print(len(test_dataset))\n",
        "print(test_dataset.X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51PT-uPVzE8_"
      },
      "source": [
        "## DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2k3YVBoxRnF",
        "outputId": "e7a9d397-7b18-4cb6-8b35-84c74644b321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "875\n",
            "219\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# shuffle the train data\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# do not shuffle the val & test data\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# dataset size // batch_size\n",
        "print(len(train_dataloader))\n",
        "print(len(test_dataloader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN65oTBk1d4T"
      },
      "source": [
        "## Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OJqIwSltn9uY"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, trainloader, testloader, model, optimizer, criterion, device):\n",
        "        \"\"\"\n",
        "        trainloader: train data's loader\n",
        "        testloader: test data's loader\n",
        "        model: model to train\n",
        "        optimizer: optimizer to update your model\n",
        "        criterion: loss function\n",
        "        \"\"\"\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "        \n",
        "    def train(self, epoch = 1):\n",
        "        self.model.train()\n",
        "        for e in range(epoch):\n",
        "            running_loss = 0.0  \n",
        "            for i, data in enumerate(self.trainloader, 0): \n",
        "                inputs, labels = data \n",
        "                # model에 input으로 tensor를 gpu-device로 보낸다\n",
        "                inputs = inputs.to(self.device)  \n",
        "                labels = labels.to(self.device)\n",
        "                # zero the parameter gradients\n",
        "                self.optimizer.zero_grad()    \n",
        "                # forward + backward + optimize\n",
        "                outputs = self.model(inputs) \n",
        "                loss = self.criterion(outputs, labels)  \n",
        "                loss.backward() \n",
        "                self.optimizer.step() \n",
        "                running_loss += loss.item()\n",
        "            \n",
        "            print('epoch: %d  loss: %.3f' % (e + 1, running_loss / len(self.trainloader)))\n",
        "            running_loss = 0.0\n",
        "        \n",
        "    def test(self):\n",
        "        self.model.eval() \n",
        "        correct = 0\n",
        "        for inputs, labels in self.testloader:\n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            output = self.model(inputs) \n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max \n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        test_acc = correct / len(self.testloader.dataset)\n",
        "        print('test_acc: %.3f' %(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1GnKJCB4T_Q"
      },
      "source": [
        "# 2. Activation Function\n",
        "\n",
        "**sigmoid function** vs **relu function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUhK8GHx0704"
      },
      "source": [
        "- input: 784\n",
        "- hidden: 32 or (32, 32)\n",
        "- output: 10\n",
        "- **activation: sigmoid or relu**\n",
        "- optimizer: sgd\n",
        "- loss: cross-entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zPmZhpZlZkQ"
      },
      "source": [
        "## 2-layer Network + Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPfV0OTc4Xdr",
        "outputId": "ef34ca38-a1aa-4d87-cb50-12c844f05f88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 hidden_dim=32, \n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKqcfL4_qK6Q",
        "outputId": "baf78465-ab93-41ef-96cc-ea32bcdff333"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1  loss: 2.161\n",
            "epoch: 2  loss: 1.755\n",
            "epoch: 3  loss: 1.326\n",
            "epoch: 4  loss: 1.037\n",
            "epoch: 5  loss: 0.855\n",
            "epoch: 6  loss: 0.734\n",
            "epoch: 7  loss: 0.649\n",
            "epoch: 8  loss: 0.588\n",
            "epoch: 9  loss: 0.541\n",
            "epoch: 10  loss: 0.505\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgD1bTOzqK-n",
        "outputId": "a17aaf10-825d-48fd-b84e-9bc55e579933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_acc: 0.882\n"
          ]
        }
      ],
      "source": [
        "trainer.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKxP2nzvVC_O"
      },
      "source": [
        "## 2-layer Network + ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gRfskIWWQEf",
        "outputId": "b37cbabc-f57a-48aa-8c44-234b9550d5af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 hidden_dim=32, \n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVKoXvlYryMK",
        "outputId": "36595e96-810c-4849-a70c-c95c87eaa0b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1  loss: 1.250\n",
            "epoch: 2  loss: 0.515\n",
            "epoch: 3  loss: 0.406\n",
            "epoch: 4  loss: 0.364\n",
            "epoch: 5  loss: 0.339\n",
            "epoch: 6  loss: 0.322\n",
            "epoch: 7  loss: 0.309\n",
            "epoch: 8  loss: 0.298\n",
            "epoch: 9  loss: 0.289\n",
            "epoch: 10  loss: 0.281\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0wcOPU_ryOg",
        "outputId": "0eba3d47-d718-446c-bdb6-1f12fc69d75b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_acc: 0.920\n"
          ]
        }
      ],
      "source": [
        "trainer.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D2tIM62sUW4"
      },
      "source": [
        "## 3-layer Network + Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29TauDy4ryQ0",
        "outputId": "6a852a3d-bf39-4b3e-c91b-89ae94945dc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 hidden_dim=(32,32), \n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oS8LPa6ryVd",
        "outputId": "7892d5dc-d4ab-47b4-a3cd-2ecf6c444f3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1  loss: 2.303\n",
            "epoch: 2  loss: 2.295\n",
            "epoch: 3  loss: 2.289\n",
            "epoch: 4  loss: 2.280\n",
            "epoch: 5  loss: 2.265\n",
            "epoch: 6  loss: 2.236\n",
            "epoch: 7  loss: 2.182\n",
            "epoch: 8  loss: 2.086\n",
            "epoch: 9  loss: 1.949\n",
            "epoch: 10  loss: 1.784\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfCOr5-lryZy",
        "outputId": "1380217d-ac01-407d-da34-7b2f059d2a79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_acc: 0.522\n"
          ]
        }
      ],
      "source": [
        "trainer.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zPtZFsZtAVy"
      },
      "source": [
        "## 3-layer Network + ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xucFjeWLryd-",
        "outputId": "e1ba0c0d-862e-40e2-a4a8-284591d1991b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 hidden_dim=(32,32), \n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQPzJum6t34S",
        "outputId": "d1f17aee-ec35-49e0-97aa-d405dc6fb06f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1  loss: 1.857\n",
            "epoch: 2  loss: 0.703\n",
            "epoch: 3  loss: 0.453\n",
            "epoch: 4  loss: 0.378\n",
            "epoch: 5  loss: 0.342\n",
            "epoch: 6  loss: 0.318\n",
            "epoch: 7  loss: 0.298\n",
            "epoch: 8  loss: 0.281\n",
            "epoch: 9  loss: 0.266\n",
            "epoch: 10  loss: 0.253\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfVnHhN9t4vC",
        "outputId": "075a811b-47e6-444f-f44a-21ce3f4fa549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_acc: 0.927\n"
          ]
        }
      ],
      "source": [
        "trainer.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RyAkEQEr-OV"
      },
      "source": [
        "#### **Activation Function과 layer 수에 따른 성능의 차이**\n",
        "\n",
        "\n",
        "\n",
        "1. sigmoid\n",
        "\n",
        "`Sigmoid` 함수는 binary classification 에 적절함 함수다. 일정 값을 기준으로 `0`과 `1`로 분류하는 방식이다. Deep Learning에서는 특정 임계치를 넘을 때만 활성화되기 때문에 activation function 중의 하나로 구분되는 함수다.\n",
        "\n",
        "보통 처음은 input layer, 마지막은 output layer 라고 하는데, 이 가운데 보이지 않는 부분은 hidden layer로 칭한다. 실제로 9개의 hidden layer 가 있다고 했을 때 Tensorflow에 돌려 보면 정확도가 0.5밖에 안되는.. 1개 hidden layer일때 보다도 못한 결과가 나오게 된다.\n",
        "\n",
        "이는 `backpropagation`에서의 `Vanishing Gradient` 때문에 발생한다. **2-layer 또는 3-layer 정도는 학습이 잘 되지만 더 깊은 층에서 학습이 되지 않는** 이유는 layer가 많을 경우 각각의 단계의 값을 미분해서 최초 레이어까지 결과 값을 전달해가게 되는데, 만약 내부의 hidden layer들이 모두 `sigmoid` 함수로 이루어져 있다면 각 단계에서 계산한 값은 모두 `0`과 `1` 사이의 값일 수밖에 없다. 따라서 여러 레이어를 갖고 있을 때, 최초 입력 값은 각각의 레이어에서 나온 값들을 곱해준 만큼의 결과에 영향을 주는 것이므로 최종 미분값은 결국 0에 가까운 값이 될 수 밖에 없다. 이를 경사도(기울기)가 사라지는 현상으로 본다. 최초 입력 값이 최종 결과 값에 별로 영향을 끼치지 않는다는 결론으로 수렴하게 되는 것이다.\n",
        "sigmoid 함수는 $0< n <1$ 사이의 값만 다루므로 결국 `chain rule`을 이용해 계속 값을 곱해나간다고 했을 때 결과 값이 `0`에 수렴할 수 밖에 없다는 한계를 가지고 있으므로, 나중에는 `1`보다 작아지지 않게 하기 위한 대안으로 `ReLU`라는 함수를 적용하게 된다.\n",
        "\n",
        "\n",
        "\\\\\n",
        "\n",
        "\n",
        "2. ReLU\n",
        "\n",
        "이후 내부 hidden layer를 활성화 시키는 함수로 `sigmoid`를 사용하지 않고 `ReLU`라는 활성화 함수를 사용하게 되는데, 이 함수는 쉽게 말해 0보다 작은 값이 나온 경우 0을 반환하고, 0보다 큰 값이 나온 경우 그 값을 그대로 반환하는 함수다. 0보다 큰 값일 경우 1을 반환하는 `sigmoid`와 다르다. 따라서 내부 hidden layer에는 `ReLU`를 적용하고, 마지막 output layer에서만 sigmoid 함수를 적용하면 이전에 비해 정확도가 훨씬 올라가게 된다.\n",
        "\n",
        "\\\\\n",
        "\n",
        "-> 결론적으로 활성화 함수는 입력값을 non-linear한 방식으로 출력값을 도출하기 위해 사용한다. 이를 통해 linear system을 non-linear한 system으로 바꿀 수 있게 되는 것이다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmrGO-uru01w"
      },
      "source": [
        "# 3. Optimization\n",
        "\n",
        "**SGD** vs **Momentum** vs **Adam ...**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jjuv9XW2Cij"
      },
      "source": [
        "- input: 784\n",
        "- hidden: (32, 32)\n",
        "- output: 10\n",
        "- activation: relu\n",
        "- **optimizer: sgd or momentum or adam**\n",
        "- loss: cross-entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WxhHMDjHxRV4"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 hidden_dim=(32,32), \n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlkMXZfKxpRg"
      },
      "source": [
        "## 3-layer Network + ReLU + SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCDbH1Bbxify",
        "outputId": "390dcf1b-3b3a-428b-8154-2ab55eb2bac5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MLP()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lchz9vtUxkiD",
        "outputId": "0c5637d2-a87c-4566-d400-715fb46d338b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1  loss: 1.901\n",
            "epoch: 2  loss: 0.716\n",
            "epoch: 3  loss: 0.456\n",
            "epoch: 4  loss: 0.384\n",
            "epoch: 5  loss: 0.348\n",
            "epoch: 6  loss: 0.323\n",
            "epoch: 7  loss: 0.303\n",
            "epoch: 8  loss: 0.288\n",
            "epoch: 9  loss: 0.275\n",
            "epoch: 10  loss: 0.264\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ksQiJFqxls_",
        "outputId": "4f0cce02-f6f1-49ef-97bf-59ca6a826350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_acc: 0.922\n"
          ]
        }
      ],
      "source": [
        "trainer.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1nhBnqWxw4a"
      },
      "source": [
        "## 3-layer Network + ReLU + Momentum\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idG8_h_QxmQi",
        "outputId": "c0088e38-95b9-42d8-faa1-7077022a6654"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MLP()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.99)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDNAysVqxxOk",
        "outputId": "78a7c551-dd80-411b-c2fd-97b530d8fe11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1  loss: 0.596\n",
            "epoch: 2  loss: 0.276\n",
            "epoch: 3  loss: 0.222\n",
            "epoch: 4  loss: 0.196\n",
            "epoch: 5  loss: 0.201\n",
            "epoch: 6  loss: 0.166\n",
            "epoch: 7  loss: 0.159\n",
            "epoch: 8  loss: 0.177\n",
            "epoch: 9  loss: 0.151\n",
            "epoch: 10  loss: 0.137\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0U2s0hux_n6",
        "outputId": "5fcde9fb-d86d-49f9-c9c3-5635f8911b49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_acc: 0.947\n"
          ]
        }
      ],
      "source": [
        "trainer.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZobOWhPxytT"
      },
      "source": [
        "## 3-layer Network + ReLU + Adam\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7xVOWgZxzoS",
        "outputId": "b4c66ffe-f97b-44c1-be70-7fe2d7c380fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MLP()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R4pzcKPyFBi",
        "outputId": "cb0a9864-29a2-4ffd-b799-b5ac4b80e1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1  loss: 0.296\n",
            "epoch: 2  loss: 0.171\n",
            "epoch: 3  loss: 0.147\n",
            "epoch: 4  loss: 0.142\n",
            "epoch: 5  loss: 0.126\n",
            "epoch: 6  loss: 0.125\n",
            "epoch: 7  loss: 0.119\n",
            "epoch: 8  loss: 0.114\n",
            "epoch: 9  loss: 0.112\n",
            "epoch: 10  loss: 0.104\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgAEpCJ_yHAi",
        "outputId": "dd9ac5bc-3830-4170-dcd3-c3dc97ecb5bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_acc: 0.954\n"
          ]
        }
      ],
      "source": [
        "trainer.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzL64Hzy7pUZ"
      },
      "source": [
        "### Stochastic Gradient Descent (SGD)\n",
        "SGD는 현재 위치에서 기울어진 방향이 전체적인 최솟값과 다른 방향을 가리키므로 지그재그 모양으로 탐색해나간다. 즉, SGD의 단점은 비등방성(anisotropy)함수에서는 탐색 경로가 비효율적이라는 것이다. 무작정 기울어진 방향으로 나아가는 방식보다 더 효율적인 방식이 필요하다. SGD를 보완한 기법으로 Momentum, AdaGrad, Adam이 있다.\n",
        "```python\n",
        "class SGD:\n",
        "    def __init__(self, lr = 0.01):\n",
        "        self.lr = lr\n",
        "        \n",
        "    def update(self, params, grads):\n",
        "        for key in params.keys():\n",
        "            params[key] -= self.lr * grads[key]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD-STPX37pRy"
      },
      "source": [
        "### Momentum\n",
        "\n",
        "SGD와 달리 새로운 변수 v가 나오는데 이는 물리에서 말하는 속도(velocity)이다. Momentum은 '운동량'을 뜻하는 단어로 기울기 방향으로 힘을 받아 물체가 가속되어 공이 구르는 듯한 움직임을 보인다. 위의 식에서 알파가 가속도와 관련된 파라미터이다. SGD와 최적화 과정을 비교하면 지그재그 정도가 덜하다. x축의 힘은 작지만 방향이 변하지 않으므로 일정하게 가속하여 SGD보다 x축 방향으로 빠르게 나아가므로 지그재그 정도가 덜한 것이다.\n",
        "\n",
        "```python\n",
        "class Momentum:\n",
        "    def __init__(self, ir = 0.01, momentum = 0.9):\n",
        "        self.lr = lr\n",
        "        self.momentum = momemtum\n",
        "        self.v = None\n",
        "        \n",
        "    def update(self, params, grads):\n",
        "        if self.v is None:\n",
        "            self.v = {}\n",
        "            for key, val in params.items():\n",
        "                self.v[key] = np.zeros_like(val)\n",
        "            \n",
        "            for key in parmas.keys():\n",
        "                self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
        "                params[key] += self.v[key]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw0Q9K0m7pPR"
      },
      "source": [
        "### Adam\n",
        "\n",
        "공 구르는 듯한 Momentum과 적응적인 AdaGrad를 융합한 기법이 Adam이다. Adam은 학습률, 일차 모멘텀용 계수, 이차 모멘텀용 계수로 3개의 hyperparameter를 설정한다. 일차 모멘텀용 계수=0.9, 이차 모멘텀용 계수=0.999를 기본 설정값으로 하면 보통 좋은 결과를 얻을 수 있다.\n",
        "\n",
        "\\\\\n",
        "\n",
        "- **AdaGrad**\n",
        "\n",
        "신경망 학습에서 학습률(learning rate)을 적절하게 설정하는 것이 중요하다. 학습률을 적절하게 설정하기 위해 학습률 감소(learning rate decay)라는 기술을 사용하는데 이는 학습 진행 중에 learning rate을 줄여가는 방법이다. 즉 처음에는 크게 학습을 하다가 점점 작게 학습한다는 의미이다. 이 방법을 발전시킨 것이 AdaGrad이며 AdaGrad는 각 매개변수에 Adaptive하게 조정하여 맞춤형 learning rate을 만든다.\n",
        "\n",
        "SGD와 달리 새로운 변수 h가 나오는데 이는 기존의 기울기 값을 제곱한 값을 더하여 학습률을 조정하기 위한 변수이다(⊙기호는 행렬의 원소별 곱셈을 의미함). 매개변수의 원소 중 크게 갱신된 원소는 학습률이 낮아지며 학습률 감소가 매개변수의 원소마다 다르게 적용된다.\n",
        "\n",
        "```python\n",
        "class AdaGrad:\n",
        "    def __init__(self, lr = 0.01):\n",
        "        self.lr = lr\n",
        "        self.h = None\n",
        "        \n",
        "    def update(self, params, grads):\n",
        "        if self.h is None:\n",
        "            self.h = {}\n",
        "            for key, val in params.items():\n",
        "                self.h[key] = np.zeros_like(val)\n",
        "                \n",
        "        for key in params.keys():\n",
        "            self.h[key] += grads[key] * grads[key]\n",
        "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNP78kE2zbPQ"
      },
      "source": [
        "## 4. Regularization\n",
        "\n",
        "image data batch-normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1YretVf2eRy"
      },
      "source": [
        "- input: 784\n",
        "- hidden: 32 or (32, 32)\n",
        "- output: 10\n",
        "- activation: relu\n",
        "- optimizer: adam\n",
        "- **regularizer: batch_norm**\n",
        "- loss: cross-entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmvn2oNj0Spe"
      },
      "source": [
        "## 3-layer Network + ReLU + Adam + batch_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7FBt1qcYzrph"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 hidden_dim=(32,32), \n",
        "                 output_dim=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim[0])\n",
        "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dim[1])\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VSAzG4uz_4i",
        "outputId": "c4288f6c-0f38-46e4-d765-683471e0da25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MLP()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDYfHC9x0BKy",
        "outputId": "f638e890-eea7-4980-8659-bdb44f74f6e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1  loss: 0.257\n",
            "epoch: 2  loss: 0.141\n",
            "epoch: 3  loss: 0.116\n",
            "epoch: 4  loss: 0.101\n",
            "epoch: 5  loss: 0.091\n",
            "epoch: 6  loss: 0.086\n",
            "epoch: 7  loss: 0.079\n",
            "epoch: 8  loss: 0.075\n",
            "epoch: 9  loss: 0.071\n",
            "epoch: 10  loss: 0.068\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdpSN6uu0CZy",
        "outputId": "fa5ed86d-08fc-482f-ecf9-2bd90aa9827a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_acc: 0.971\n"
          ]
        }
      ],
      "source": [
        "trainer.test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qDotwtf3m-Q",
        "outputId": "b583dbd8-c613-4700-a879-112d63d75564"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26634"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WSYxs4F0Kbt"
      },
      "source": [
        "#### Batch Normalization\n",
        "\n",
        "``` markdown\n",
        "각 레이어의 입력의 분산을 평균 0, 표준편차 1인 입력값으로 정규화 시키는 방법을 Whitening 이라고 하는데 들어오는 입력값의 특징들을 uncorrelated 하게\n",
        "만들어주고, 각각의 분산을 1로 만들어주는 작업이다. 이는 covariance matrix의 계산과 inverse의 계산이 필요하기 때문에 계산량이 많을 뿐더러, Whitening은 \n",
        "일부 파라미터들의 영향이 무시된다. 예를 들어 입력 값 X를 받아 Z = WX + b라는 결과를 내놓고 적절한 bias b 를 학습하려는 네트워크에서 Z에 E(Z) 를 \n",
        "빼주는 작업을 한다고 생각해보면, 이 과정에서 b 값이 결국 빠지게 되고, 결과적으로 b의 영향은 없어지게 된다.\n",
        "```\n",
        "\n",
        "Whitening의 문제점을 해결하도록 한 트릭이 **Batch Normalization**이다. 배치 정규화는 평균과 분산을 조정하는 과정이 별도의 과정으로 떼어진 것이 아니라, 신경망 안에 포함되어 학습 시 평균과 분산을 조정하는 과정 역시 같이 조절된다는 점이 단순 Whitening 과는 구별된다. 즉, 각 레이어마다 정규화 하는 레이어를 두어, 변형된 분포가 나오지 않도록 조절하게 하는 것이 배치 정규화이다. \n",
        "\n",
        "배치 정규화는 간단히 말하자면 미니배치의 평균과 분산을 이용해서 정규화 한 뒤에, scale 및 shift 를 감마(γ) 값, 베타(β) 값을 통해 실행한다. 이 때 감마와 베타 값은 학습 가능한 변수이다. 즉, Backpropagation을 통해서 학습이 된다.\n",
        "\n",
        "정규화 된 값을 활성화 함수의 입력으로 사용하고, 최종 출력 값을 다음 레이어의 입력으로 사용하는 것이다.\n",
        "\n",
        "기존 $output = g(Z),\\ Z = WX + b$ 식은 $output = g(BN(Z)),\\ Z = WX + b$ 로 변경되는 것이다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6xu4cQl0fOy"
      },
      "source": [
        "# 5. Fully-Connected Layer vs Convolution Layer\n",
        "\n",
        "모든 layer를 fully-connected layer로 만드는 것은 엄청난 파라미터와 연산량을 필요로 하기 때문에 더욱 큰 고화질의 이미지 데이터를 처리하는데는 적합하지 않다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBH4WROS2-H4"
      },
      "source": [
        "## Convolution Operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "-tfEDx7429cL"
      },
      "outputs": [],
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 output_dim=10):\n",
        "        super(Conv, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=7,\n",
        "                               stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=8,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=7,\n",
        "                               stride=2)\n",
        "        self.fc = nn.Linear(3*3*8, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # should reshape data into image\n",
        "        x = x.reshape(-1, 1, 28, 28)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = x.reshape(-1, 3*3*8)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2QbRqEz-FzB",
        "outputId": "8ce28f71-a045-4d89-b0a9-30c809f7fe5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Conv(\n",
              "  (conv1): Conv2d(1, 8, kernel_size=(7, 7), stride=(2, 2))\n",
              "  (conv2): Conv2d(8, 8, kernel_size=(7, 7), stride=(2, 2))\n",
              "  (fc): Linear(in_features=72, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Conv()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTRB0_15-eYy",
        "outputId": "80e6e7ec-1399-468b-c3d4-7266fe53400f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1  loss: 0.190\n",
            "epoch: 2  loss: 0.090\n",
            "epoch: 3  loss: 0.084\n",
            "epoch: 4  loss: 0.076\n",
            "epoch: 5  loss: 0.076\n",
            "epoch: 6  loss: 0.075\n",
            "epoch: 7  loss: 0.072\n",
            "epoch: 8  loss: 0.069\n",
            "epoch: 9  loss: 0.076\n",
            "epoch: 10  loss: 0.067\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuFiCnDa-fpC",
        "outputId": "158e56fa-bae9-423b-9e98-ab5795f6de6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_acc: 0.973\n"
          ]
        }
      ],
      "source": [
        "trainer.test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRVwFbhU-8TZ",
        "outputId": "4f1bbf73-630e-4a07-fb11-35a66767fe38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4274"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGBJzVaeAoNi"
      },
      "source": [
        "고전적인 신경망 구조는 컴퓨터 영상 인식 작업에 비효율적인 것으로 밝혀졌다. 이미지는 신경 네트워크에 대한 대용량 이미지의 입력(수백 또는 수천 픽셀과 최대 3가지 색 채널을 가짐)을 하게 되므로 이 입력에 대한 처리 속도를 못 따라간다. 하지만 컴퓨팅 시스템의 발전으로 이와 같은 문제가 해결되었다.\n",
        "\n",
        "​FCN(Fully Connected Networks)에서는 엄청난 수의 연결과 네트워크 매개변수를 필요로 한다. CNN Architectures은 입력 이미지가 각각의 객체나 사물의 특징으로 구성되었다는 데이터를 활용하고, 각 객체 및 형상들을 분리하여 해석하는 메커니즘을 만들어 전체적인 이미지가 무엇인지 알려준다.\n",
        "\n",
        "또한, CNN 네트워크의 일부로서, convolution/pooling 네트워크 프로세스의 최종 결과를 취하여 분류 결정에 도달하는 완전히 연결된 계층(Fully Connected Layer)이 있다.\n",
        "\n",
        "Fully connected layer의 목적은 Convolution/Pooling 프로세스의 결과를 취하여 이미지를 정의된 라벨로 분류하는 데 사용한다.\n",
        "\n",
        "Convolution/Pooling 의 출력은 각각 특정 입력 이미지내의 객체가 라벨에 속할 확률을 나타내는 값의 단일 벡터로 평탄화 된다. 예를 들어, 이미지가 고양이인 경우, 수염이나 털과 같은 것을 나타내는 형상은 \"cat\" 라벨에 대한 높은 확률을 가져야 한다.\n",
        "\n",
        "미리 학습된 Weight에 의해 계산되어지고 인공신경망에서처럼 활성화 함수(일반적으로 ReLu)를 통과하고 출력층으로 전달되는데, 그 안에서 모든 뉴런은 이미 정의된 분류 라벨을 나타낸다.​\n",
        "\n",
        "FC(Fully connected layer)를 정의하자면, 완전히 연결 되었다라는 뜻으로, 한 층의 모든 뉴런이 다음층이 모든 뉴런과 연결된 상태로 2차원의 배열 형태 이미지를 1차원의 평탄화 작업을 통해 이미지를 분류하는데 사용되는 계층이다.\n",
        "\n",
        "\n",
        "1. 2차원 배열 형태의 이미지를 1차원 배열로 평탄화\n",
        "\n",
        "2. 활성화 함수(Relu, Leaky Relu, Tanh,등)뉴런을 활성화\n",
        "\n",
        "3. 분류기(Softmax) 함수로 분류\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayzu25pm_KNH"
      },
      "source": [
        "완전히 연결된 계층에 대한 컨볼루션 계층의 강점은 정확히 그것들이 완전히 연결된 계층보다 더 좁은 범위의 특징을 나타낸다는 것이다. 완전히 연결된 층의 뉴런은 앞의 층의 모든 뉴런에 연결되어 있으므로 앞의 층의 뉴런 중 하나가 변경되면 변경될 수 있다. 그러나 컨볼루션 레이어의 뉴런은 컨볼루션 커널의 너비 내에서 이전 레이어의 \"근처\" 뉴런에만 연결된다. 결과적으로, 컨볼루션 레이어의 뉴런들은 이전 레이어의 뉴런들 대부분의 활성화에 민감하지 않다는 점에서 더 좁은 범위의 특징들을 나타낼 수 있다.\n",
        "\n",
        "이러한 방식으로 기능 범위를 제한하면 대부분의 정보가 로컬일 것으로 예상되는 경우에 유용할 수 있습니다. 예를 들어, 이미지 분류에서 새는 이미지의 위치와 이미지의 다른 곳에 자동차가 있는지 여부에 관계없이 새의 위치에 있는 픽셀을 기준으로 새처럼 보입니다. 이 사전 예상의 유용성은 완전히 무작위 가중치를 가진 CNN조차도 완전히 훈련된 CNN만큼 분류에 유용한 기능을 제공한다는 관찰에 의해 도출된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdCwjzXX_-jU"
      },
      "source": [
        "### under 20000 Parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u86dyWA98qQ_"
      },
      "source": [
        "$$\n",
        "Output\\ height = (Input\\ height + padding\\ height\\ top + padding\\ height\\ bottom - kernel\\ height) / (stride\\ height) + 1\\\\\\ \\\\ \n",
        "Output\\ width = (Output\\ width + padding\\ width\\ right + padding\\ width\\ left - kernel\\ width) / (stride\\ width) + 1\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "nOqAaJkGAAuC"
      },
      "outputs": [],
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim=784, \n",
        "                 output_dim=10):\n",
        "        super(CustomModel, self).__init__()\n",
        "        #28*28*1\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=(7, 7),\n",
        "                               stride=2)\n",
        "        #14*14*8\n",
        "        self.conv2 = nn.Conv2d(in_channels=8,\n",
        "                               out_channels=16,\n",
        "                               kernel_size=(7,7),\n",
        "                               stride=1)\n",
        "        #7*7*16\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
        "        self.fc = nn.Linear(8*8, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # should reshape data into image\n",
        "        x = x.reshape(-1, 1, 28, 28)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = F.softmax(x)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B-6gww_Af0E",
        "outputId": "1d2e8766-b64b-4a75-c215-7b44d693c03f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9098\n"
          ]
        }
      ],
      "source": [
        "model = CustomModel()\n",
        "print(count_parameters(model))\n",
        "if count_parameters(model) > 20000:\n",
        "  raise AssertionError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcA3XbRUAaUh",
        "outputId": "27d6f624-0b38-4c6a-cf22-95a961da6672"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CustomModel(\n",
              "  (conv1): Conv2d(1, 8, kernel_size=(7, 7), stride=(2, 2))\n",
              "  (conv2): Conv2d(8, 16, kernel_size=(7, 7), stride=(1, 1))\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJBKdQTyAd24",
        "outputId": "e3cec582-db05-4948-a205-62ac724ef245"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-57-173cb3bcb9c4>:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = F.softmax(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1  loss: 0.046\n",
            "epoch: 2  loss: 0.044\n",
            "epoch: 3  loss: 0.043\n",
            "epoch: 4  loss: 0.041\n",
            "epoch: 5  loss: 0.039\n",
            "epoch: 6  loss: 0.038\n",
            "epoch: 7  loss: 0.037\n",
            "epoch: 8  loss: 0.035\n",
            "epoch: 9  loss: 0.034\n",
            "epoch: 10  loss: 0.033\n",
            "epoch: 11  loss: 0.032\n",
            "epoch: 12  loss: 0.031\n",
            "epoch: 13  loss: 0.029\n",
            "epoch: 14  loss: 0.029\n",
            "epoch: 15  loss: 0.028\n",
            "epoch: 16  loss: 0.027\n",
            "epoch: 17  loss: 0.026\n",
            "epoch: 18  loss: 0.025\n",
            "epoch: 19  loss: 0.025\n",
            "epoch: 20  loss: 0.024\n",
            "epoch: 21  loss: 0.023\n",
            "epoch: 22  loss: 0.022\n",
            "epoch: 23  loss: 0.021\n",
            "epoch: 24  loss: 0.021\n",
            "epoch: 25  loss: 0.020\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(trainloader = train_dataloader,\n",
        "                  testloader = test_dataloader,\n",
        "                  model = model,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  device = device)\n",
        "\n",
        "trainer.train(epoch = 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0URQgBu_AfJB",
        "outputId": "33dbf290-9d88-4cf7-ca53-e76ca4d36162"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-57-173cb3bcb9c4>:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = F.softmax(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_acc: 0.982\n"
          ]
        }
      ],
      "source": [
        "trainer.test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp_V8lHJH2lR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
