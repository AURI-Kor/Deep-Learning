{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR26RFkwXtvi"
      },
      "source": [
        "# **LR vs MLP**\n",
        "2023-01-27\n",
        "\n",
        "Model & Trainer\n",
        "\n",
        "모델의 학습 Process\n",
        "1. Initilaize Dataset and DataLoader\n",
        "2. Initialize Model\n",
        "3. Train Model\n",
        "\n",
        "Mnist dataset을 활용한 logistic regression model과 MLP model의 성능 비교 및 파이프라인 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4iquuOQj1g9"
      },
      "source": [
        "# 1. Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqVdEuPQzMAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eda1a7b-cc88-4313-fd55-2d502a4008a5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o3-HPdHLZma"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMkIJgfEl9kD"
      },
      "source": [
        "# 2. Preprocess Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8XqtZa8sXsw"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCnmrA9ltYs0"
      },
      "source": [
        "mnist = fetch_openml('mnist_784', cache=False)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5m4qus2UnoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f73df0-3a3c-479b-bd4d-f27cc1d095a5"
      },
      "source": [
        "mnist.data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BfwipaTYEFI"
      },
      "source": [
        "## Preprocess Dataset\n",
        "\n",
        "Mnist Dataset의 image는 각각 28*28의 픽셀로 구성된 784차원 짜리 벡터로 나타나져 있다. 각 픽셀은 0-255사이의 값으로 흰색부터 검은색 사이의 값을 나타낸다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upkEJ9mBMCOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0dd923d-f0b9-4ddc-e019-f56d4465752e"
      },
      "source": [
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')\n",
        "X = X.values\n",
        "y = y.values\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784)\n",
            "(70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obZ-A5rxYOSx"
      },
      "source": [
        "값이 너무 커지는 것을 방지하기 위해 [0,255]사이의 input을 [0,1]의 scale로 조정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkJRGOaEyyc0"
      },
      "source": [
        "X /= 255.0"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk1OASeazKtN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69520b5-540a-42b3-c12b-9b1f2ea21e97"
      },
      "source": [
        "print(X.min(), X.max())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-u3e9taDjT"
      },
      "source": [
        "## Split Train/Test Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HWWRcNjaLDi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ee52d4-ee2d-4e5e-905a-7ae5f12c9cc1"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5)\n",
        "print(X_train.shape) # 80%\n",
        "print(y_train.shape)\n",
        "print(X_val.shape) # 10%\n",
        "print(y_val.shape)\n",
        "print(X_test.shape) # 10%\n",
        "print(y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56000, 784)\n",
            "(56000,)\n",
            "(7000, 784)\n",
            "(7000,)\n",
            "(7000, 784)\n",
            "(7000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A7LymV5aYEA"
      },
      "source": [
        "## Visualize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "cnt = 1\n",
        "for i in X[0]:\n",
        "  if cnt > 28:\n",
        "    cnt = 1\n",
        "    print()\n",
        "  if math.ceil(float(i)) == 0:\n",
        "    print('■', end='')\n",
        "  else:\n",
        "    print('□', end='')\n",
        "  cnt+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkqL45QuYG5f",
        "outputId": "b363bd41-0e03-4717-f8f8-4cc423d82585"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
            "■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
            "■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
            "■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
            "■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
            "■■■■■■■■■■■■□□□□□□□□□□□□■■■■\n",
            "■■■■■■■■□□□□□□□□□□□□□□□□■■■■\n",
            "■■■■■■■□□□□□□□□□□□□□□□□■■■■■\n",
            "■■■■■■■□□□□□□□□□□□■■■■■■■■■■\n",
            "■■■■■■■■□□□□□□□■□□■■■■■■■■■■\n",
            "■■■■■■■■■□□□□□■■■■■■■■■■■■■■\n",
            "■■■■■■■■■■■□□□□■■■■■■■■■■■■■\n",
            "■■■■■■■■■■■□□□□■■■■■■■■■■■■■\n",
            "■■■■■■■■■■■■□□□□□□■■■■■■■■■■\n",
            "■■■■■■■■■■■■■□□□□□□■■■■■■■■■\n",
            "■■■■■■■■■■■■■■□□□□□□■■■■■■■■\n",
            "■■■■■■■■■■■■■■■□□□□□■■■■■■■■\n",
            "■■■■■■■■■■■■■■■■■□□□□■■■■■■■\n",
            "■■■■■■■■■■■■■■□□□□□□□■■■■■■■\n",
            "■■■■■■■■■■■■□□□□□□□□■■■■■■■■\n",
            "■■■■■■■■■■□□□□□□□□□■■■■■■■■■\n",
            "■■■■■■■■□□□□□□□□□□■■■■■■■■■■\n",
            "■■■■■■□□□□□□□□□□■■■■■■■■■■■■\n",
            "■■■■□□□□□□□□□□■■■■■■■■■■■■■■\n",
            "■■■■□□□□□□□□■■■■■■■■■■■■■■■■\n",
            "■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
            "■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
            "■■■■■■■■■■■■■■■■■■■■■■■■■■■■"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpFTKldSQFiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "522ad270-975a-4b46-8375-e1a1a05bad65"
      },
      "source": [
        "X[:5]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKvYqt3ZaOXZ"
      },
      "source": [
        "def plot_example(X, y):\n",
        "    \"\"\"Plot the first 5 images and their labels in a row.\"\"\"\n",
        "    for i, (img, y) in enumerate(zip(X[:5].reshape(5, 28, 28), y[:5])):\n",
        "        plt.subplot(151 + i)\n",
        "        plt.imshow(img)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(y)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHkBF7cejNC1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "66b6add8-5630-48d3-bff2-31cbd80ade78"
      },
      "source": [
        "plot_example(X_train, y_train)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYnvqbdijWUQ"
      },
      "source": [
        "# 3. Pytorch Dataset \n",
        "\n",
        "PyTorch에서는 Custom Dataset을 사용하기 위해서는 torch.utils.data.Dataset의 형태로 dataset class를 정의해준 이후, torch.utils.data.DataLoader의 형태로 dataloader class를 정의하여 학습시에 model에 forwarding할 data를 sample 해주어야 한다.\n",
        "\n",
        "(https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75WjNxMrzCOb"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y_5YkXSybCA"
      },
      "source": [
        "가장 보편적으로 사용되는 map-style의 dataset class는 torch.utils.data.Dataset을 superclass로 받아 __getitem__()과 __len__()함수를 override해준다.\n",
        "\n",
        "```\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    return self.data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypqp7zA-xRlB"
      },
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        super(CustomDataset, self).__init__()\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.X[index]\n",
        "        y = self.y[index]\n",
        "        x = torch.from_numpy(x).float()\n",
        "        y = torch.from_numpy(np.array(y)).long()\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTr4OWatzmaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d628673-8eee-4acd-9b83-0ff420e2090e"
      },
      "source": [
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "val_dataset = CustomDataset(X_val, y_val)\n",
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(train_dataset.X.shape)\n",
        "print(len(val_dataset))\n",
        "print(val_dataset.X.shape)\n",
        "print(len(test_dataset))\n",
        "print(test_dataset.X.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56000\n",
            "(56000, 784)\n",
            "7000\n",
            "(7000, 784)\n",
            "7000\n",
            "(7000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51PT-uPVzE8_"
      },
      "source": [
        "## DataLoader\n",
        "\n",
        "DataLoader는 train 혹은 validation시 dataset에서 batch를 sampling하기 위한 API다. (https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n",
        "\n",
        "필수적으로 사용하는 option\n",
        "- dataset: sampling할 dataset\n",
        "- batch_size: 한번에 sampling할 dataset의 개수\n",
        "- shuffle: 1 epoch를 기준으로 dataset을 shuffle할지"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2k3YVBoxRnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0faef41c-2a57-4e73-ec5e-a60d488d89ee"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# shuffle the train data\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# do not shuffle the val & test data\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# dataset size // batch_size\n",
        "print(len(train_dataloader))\n",
        "print(len(val_dataloader))\n",
        "print(len(test_dataloader))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "875\n",
            "110\n",
            "110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN65oTBk1d4T"
      },
      "source": [
        "# 4. Model\n",
        "\n",
        "\n",
        "Pytorch에서 model을 선언할 때는 torch.nn.Module class를 superclass로 받아 __init__()함수와 forward() 함수를 작성한다.\n",
        "\n",
        "__init__()함수에는 모델의 파라미터들을 선언하고, forward함수에는 해당 파라미터들을 이용하여 data를 model에 통과시킨다.\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6scAJcC11KR"
      },
      "source": [
        "## Initialize Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9fPzVmH1dZF"
      },
      "source": [
        "class LR(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LR, self).__init__()\n",
        "        self.fc = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3wsp8tJ2w4e"
      },
      "source": [
        "## Initialize MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6_0LrGL1ddk"
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1GnKJCB4T_Q"
      },
      "source": [
        "# 5. Train\n",
        "\n",
        "이제 선언한 model을 통해 학습을 진행하기 위해서는 model의 파라미터를 최적화할 optimizer가 필요하다. 가장 보편적으로 사용되는 `Adam`을 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zPmZhpZlZkQ"
      },
      "source": [
        "### Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPfV0OTc4Xdr"
      },
      "source": [
        "class Trainer():\n",
        "    def __init__(self, trainloader, valloader, testloader, model, optimizer, criterion, device):\n",
        "        \"\"\"\n",
        "        trainloader: train data's loader\n",
        "        testloader: test data's loader\n",
        "        model: model to train\n",
        "        optimizer: optimizer to update your model\n",
        "        criterion: loss function\n",
        "        \"\"\"\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.testloader = testloader\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "        \n",
        "    def train(self, epoch = 1):\n",
        "        # 학습을 시작할 때 model을 train-mode로 바꿔주어야함.\n",
        "        self.model.train()\n",
        "        for e in range(epoch):\n",
        "            running_loss = 0.0  \n",
        "            for i, data in enumerate(self.trainloader, 0): \n",
        "                inputs, labels = data \n",
        "                # model에 input으로 tensor를 gpu-device로 보낸다\n",
        "                inputs = inputs.to(self.device)  \n",
        "                labels = labels.to(self.device)\n",
        "                # zero the parameter gradients -> pytorch에는 미분한 값들이 누적되는 특징이 있기 때문\n",
        "                self.optimizer.zero_grad()    \n",
        "                # forward + backward + optimize\n",
        "                # get output after passing through the network\n",
        "                outputs = self.model(inputs) \n",
        "                # compute model's score using the loss function\n",
        "                loss = self.criterion(outputs, labels)  \n",
        "                # perform back-propagation from the loss\n",
        "                loss.backward() \n",
        "                # gradient descent를 통해 model의 output을 얻는다.\n",
        "                self.optimizer.step() \n",
        "                running_loss += loss.item()\n",
        "            \n",
        "            print('epoch: %d  loss: %.3f' % (e + 1, running_loss / len(self.trainloader)))\n",
        "            running_loss = 0.0\n",
        "        val_acc = self.validate()\n",
        "        return val_acc\n",
        "\n",
        "    def validate(self):\n",
        "        self.model.eval() \n",
        "        correct = 0\n",
        "        for inputs, labels in self.valloader:\n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            output = self.model(inputs) \n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max \n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        return correct / len(self.valloader.dataset)\n",
        "        \n",
        "    def test(self):\n",
        "        self.model.eval() \n",
        "        correct = 0\n",
        "        for inputs, labels in self.testloader:\n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            output = self.model(inputs) \n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max \n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        return correct / len(self.testloader.dataset)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training-mode & eval-mode\n",
        "\n",
        "nn.Module에는 train time과 evaluate time에 수행하는 다른 작업을 switching해줄 수 있도록하는 함수를 제공한다.\n",
        "\n",
        "train 단계는 말 그대로 모델을 학습시킨다. 그 말은 validation과 test 단계에서는 학습이 일어나지 않는다는 것이다. (training은 optimizer.step())\n",
        "\n",
        "같은 epoch에서 train이 되었다면 곧바로 validation을 해주어야 한다. 검증의 최종 목적은 최적의 epoch를 찾아 overfitting과 unseen data 문제를 막는 것이므로 검증용 데이터를 모델에 넣어 loss 함수를 확인해 training의 적합 여부를 판단한다.\n",
        "\n",
        "test는 validation step과 같으나 loss를 MAE와 같은 함수를 사용한다.\n",
        "\n",
        "train time과 evaluate time에 서로 다르게 동작해야 하는 것들에는 대표적으로 아래와 같은 것들이 있다.\n",
        "\n",
        "- `Dropout layer`\n",
        "- `BatchNorm layer`\n",
        "\n",
        "model.eval()을 수행하면 evaluation과정에서 사용하지 않을 layer들의 전원을 끈다.\n",
        "\n",
        "``` python\n",
        "# eval mode\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\t...\n",
        "    out = model(val_data)\n",
        "    ...\n",
        "```\n",
        "evaluation이 끝나면 다시 train mode로 변경을 해줘야한다.\n",
        "``` python\n",
        "# train mode\n",
        "\n",
        "model.train()\n",
        "```"
      ],
      "metadata": {
        "id": "CeNpZQ7DguV5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKxP2nzvVC_O"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gRfskIWWQEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0856ccd4-04f9-4928-9a05-494745a29711"
      },
      "source": [
        "input_dim = 784\n",
        "output_dim = 10\n",
        "epoch = 4\n",
        "device = torch.device('cuda')\n",
        "\n",
        "best_acc = 0.0\n",
        "lrs = [1e-1, 1e-2, 1e-3, 1e-4]\n",
        "for lr in lrs:\n",
        "    model = LR(input_dim=input_dim, output_dim=output_dim).to(device)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    trainer = Trainer(train_dataloader, val_dataloader, test_dataloader, model, optimizer, criterion, device)\n",
        "    val_acc = trainer.train(epoch = epoch)\n",
        "    print('val_acc: %.3f' %(val_acc))\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), './best_model')\n",
        "\n",
        "trainer.model.load_state_dict(torch.load('./best_model'))\n",
        "test_acc = trainer.test()\n",
        "print('test_acc: %.3f' %(test_acc))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1  loss: 1.161\n",
            "epoch: 2  loss: 1.173\n",
            "epoch: 3  loss: 1.269\n",
            "epoch: 4  loss: 1.315\n",
            "val_acc: 0.901\n",
            "epoch: 1  loss: 0.356\n",
            "epoch: 2  loss: 0.301\n",
            "epoch: 3  loss: 0.294\n",
            "epoch: 4  loss: 0.291\n",
            "val_acc: 0.916\n",
            "epoch: 1  loss: 0.552\n",
            "epoch: 2  loss: 0.322\n",
            "epoch: 3  loss: 0.293\n",
            "epoch: 4  loss: 0.279\n",
            "val_acc: 0.921\n",
            "epoch: 1  loss: 1.401\n",
            "epoch: 2  loss: 0.738\n",
            "epoch: 3  loss: 0.557\n",
            "epoch: 4  loss: 0.473\n",
            "val_acc: 0.890\n",
            "test_acc: 0.919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vraDZVtolBSa"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht3K2k_miraK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675fac36-7e4a-4cf6-e4b5-993913b9273c"
      },
      "source": [
        "input_dim = 784\n",
        "hidden_dim = 32\n",
        "output_dim = 10\n",
        "epoch = 4\n",
        "device = torch.device('cuda')\n",
        "\n",
        "best_acc = 0.0\n",
        "lrs = [1e-1, 1e-2, 1e-3, 1e-4]\n",
        "for lr in lrs:\n",
        "    model = MLP(input_dim=input_dim, \n",
        "                hidden_dim=hidden_dim,\n",
        "                output_dim=output_dim).to(device)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    trainer = Trainer(train_dataloader, val_dataloader, test_dataloader, model, optimizer, criterion, device)\n",
        "    val_acc = trainer.train(epoch = epoch)\n",
        "    print('val_acc: %.3f' %(val_acc))\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), './best_model')\n",
        "\n",
        "trainer.model.load_state_dict(torch.load('./best_model'))\n",
        "test_acc = trainer.test()\n",
        "print('test_acc: %.3f' %(test_acc))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1  loss: 0.861\n",
            "epoch: 2  loss: 0.835\n",
            "epoch: 3  loss: 0.897\n",
            "epoch: 4  loss: 0.939\n",
            "val_acc: 0.708\n",
            "epoch: 1  loss: 0.276\n",
            "epoch: 2  loss: 0.170\n",
            "epoch: 3  loss: 0.145\n",
            "epoch: 4  loss: 0.128\n",
            "val_acc: 0.949\n",
            "epoch: 1  loss: 0.469\n",
            "epoch: 2  loss: 0.240\n",
            "epoch: 3  loss: 0.196\n",
            "epoch: 4  loss: 0.168\n",
            "val_acc: 0.947\n",
            "epoch: 1  loss: 1.288\n",
            "epoch: 2  loss: 0.550\n",
            "epoch: 3  loss: 0.410\n",
            "epoch: 4  loss: 0.356\n",
            "val_acc: 0.903\n",
            "test_acc: 0.949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "해당 학습에서 LR에 비해 MLP가 더 높은 성능을 보여줌을 확인할 수 있다."
      ],
      "metadata": {
        "id": "I6Yj_XVPiL8q"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPeWLRy6lLHa"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}